{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3365196f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-76a01d9c502b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d9e557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x2a9330ce508>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11db5da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse text through the `nlp` model\n",
    "my_text = \"\"\"The economic situation of the country is on edge , as the stock \n",
    "market crashed causing loss of millions. Citizens who had their main investment \n",
    "in the share-market are facing a great loss. Many companies might lay off \n",
    "thousands of people to reduce labor cost\"\"\"\n",
    "\n",
    "#The Doc Object\n",
    "my_doc = nlp(my_text)\n",
    "type(my_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization with spaCy\n",
    "# Printing the tokens of a doc\n",
    "for token in my_doc:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90824a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text-Preprocessing with spaCy\n",
    "for token in my_doc:\n",
    "  print(token.text,'--',token.is_stop,'---',token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing StopWords and punctuations\n",
    "my_doc_cleaned = [token for token in my_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "for token in my_doc_cleaned:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57a5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n",
      "play\n",
      "chess\n",
      "against\n",
      "rita\n",
      "she\n",
      "like\n",
      "play\n",
      "chess\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing the tokens of a doc\n",
    "text='she played chess against rita she likes playing chess.'\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "  print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce1268ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4386335507830398018\n",
      "traveling\n"
     ]
    }
   ],
   "source": [
    "# Strings to Hashes and Back\n",
    "doc = nlp(\"I love traveling\")\n",
    "\n",
    "# Look up the hash for the word \"traveling\"\n",
    "word_hash = nlp.vocab.strings[\"traveling\"]\n",
    "print(word_hash)\n",
    "\n",
    "# Look up the word_hash to get the string\n",
    "word_string = nlp.vocab.strings[word_hash]\n",
    "print(word_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8be9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DOC 1-------\n",
      "Raymond   5945540083247941101\n",
      "shirts   9181315343169869855\n",
      "are   5012629990875267006\n",
      "famous   17809293829314912000\n",
      "-------DOC 2-------\n",
      "I   4690420944186131903\n",
      "washed   5520327350569975027\n",
      "my   227504873216781231\n",
      "shirts   9181315343169869855\n"
     ]
    }
   ],
   "source": [
    "#Interestingly, a word will have the same hash value irrespective of which document it occurs in or which spaCy model \n",
    "#is being used.\n",
    "# Create two different doc with a common word\n",
    "doc1 = nlp('Raymond shirts are famous')\n",
    "doc2 = nlp('I washed my shirts ')\n",
    "\n",
    "# Printing the hash value for each token in the doc\n",
    "\n",
    "print('-------DOC 1-------')\n",
    "for token in doc1:\n",
    "  hash_value=nlp.vocab.strings[token.text]\n",
    "  print(token.text ,' ',hash_value)\n",
    "\n",
    "print('-------DOC 2-------')\n",
    "for token in doc2:\n",
    "  hash_value=nlp.vocab.strings[token.text]\n",
    "  print(token.text ,' ',hash_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f75bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "#Lexical attributes of spaCy\n",
    "# Printing the tokens which are like numbers\n",
    "text=' 2020 is far worse than 2009'\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "  if token.like_num:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd48d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_text=' Production in chennai is 87 %. In Kolkata, produce it as low as 43 %. In Bangalore, production ia as good as 98 %.In mysore, production is average around 78 %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40ffac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "43\n",
      "98\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "# Finding the tokens which are numbers followed by % \n",
    "\n",
    "production_doc=nlp(production_text)\n",
    "\n",
    "for token in production_doc:\n",
    "  if token.like_num:\n",
    "    index_of_next_token=token.i+ 1\n",
    "    next_token=production_doc[index_of_next_token]\n",
    "    if next_token.text == '%':\n",
    "      print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02748c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koushiki@gmail.com\n",
      "gayathri1999@gmail.com\n",
      "ardra@gmail.com\n",
      "parmar15@yahoo.com\n",
      "shank@rediffmail.com\n",
      "utkarsh@gmail.com\n"
     ]
    }
   ],
   "source": [
    "#Detecting Email Addresses\n",
    "# text containing employee details\n",
    "employee_text=\"\"\" name : Koushiki age: 45 email : koushiki@gmail.com\n",
    "                 name : Gayathri age: 34 email: gayathri1999@gmail.com\n",
    "                 name : Ardra age: 60 email : ardra@gmail.com\n",
    "                 name : pratham parmar age: 15 email : parmar15@yahoo.com\n",
    "                 name : Shashank age: 54 email: shank@rediffmail.com\n",
    "                 name : Utkarsh age: 46 email :utkarsh@gmail.com\"\"\"\n",
    "\n",
    "# creating a spacy doc          \n",
    "employee_doc=nlp(employee_text)\n",
    "\n",
    "# Printing the tokens which are email through `like_email` attribute\n",
    "for token in employee_doc:\n",
    "  if token.like_email:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token.is_alpha : Returns True if the token is an alphabet\n",
    "# token.is_ascii : Returns True if the token belongs to ascii characters\n",
    "# token.is_digit : Returns True if the token is a number(0-9)\n",
    "# token.is_upper : Returns True if the token is upper case alphabet\n",
    "# token.is_lower : Returns True if the token is lower case alphabet\n",
    "# token.is_space : Returns True if the token is a space ‘ ‘\n",
    "# token.is_bracket : Returns True if the token is a bracket\n",
    "# token.is_quote : Returns True if the token is a quotation mark\n",
    "# token.like_url : Returns True if the token is similar to a URl (link to website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c62f83bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John ----  PROPN\n",
      "plays ----  VERB\n",
      "basketball ----  NOUN\n",
      ", ----  PUNCT\n",
      "if ----  SCONJ\n",
      "time ----  NOUN\n",
      "permits ----  VERB\n",
      ". ----  PUNCT\n",
      "He ----  PRON\n",
      "played ----  VERB\n",
      "in ----  ADP\n",
      "high ----  ADJ\n",
      "school ----  NOUN\n",
      "too ----  ADV\n",
      ". ----  PUNCT\n"
     ]
    }
   ],
   "source": [
    "#Part of Speech analysis with spaCy\n",
    "# POS tagging using spaCy\n",
    "my_text='John plays basketball,if time permits. He played in high school too.'\n",
    "my_doc=nlp(my_text)\n",
    "for token in my_doc:\n",
    "  print(token.text,'---- ',token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e43d572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subordinating conjunction'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('SCONJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5967aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The junk values are..\n",
      "etc\n",
      "i.e.\n",
      "i.e.\n",
      "etc\n",
      "etc\n",
      "After removing junk\n",
      "[I, liked, the, movies, The, movie, had, good, direction,  , The, movie, was, amazing, \n",
      "            , The, movie, was, average, direction, was, not, bad, The, cinematography, was, nice, ., \n",
      "            , The, movie, was, a, bit, lengthy,  , otherwise, fantastic,  ]\n"
     ]
    }
   ],
   "source": [
    "# How POS tagging helps you in dealing with text based problems.\n",
    "# Raw text document\n",
    "raw_text=\"\"\"I liked the movies etc The movie had good direction  The movie was amazing i.e.\n",
    "            The movie was average direction was not bad The cinematography was nice. i.e.\n",
    "            The movie was a bit lengthy  otherwise fantastic  etc etc\"\"\"\n",
    "\n",
    "# Creating a spacy object\n",
    "raw_doc=nlp(raw_text)\n",
    "\n",
    "# Checking if POS tag is X and printing them\n",
    "print('The junk values are..')\n",
    "for token in raw_doc:\n",
    "  if token.pos_=='X':\n",
    "    print(token.text)\n",
    "\n",
    "print('After removing junk')\n",
    "# Removing the tokens whose POS tag is junk.\n",
    "clean_doc=[token for token in raw_doc if not token.pos_=='X']\n",
    "print(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c9c4b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{95: 'PRON', 100: 'VERB', 90: 'DET', 92: 'NOUN', 101: 'X', 84: 'ADJ', 103: 'SPACE', 87: 'AUX', 94: 'PART', 97: 'PUNCT', 86: 'ADV'}\n"
     ]
    }
   ],
   "source": [
    "# creating a dictionary with parts of speeach &amp; corresponding token numbers.\n",
    "\n",
    "all_tags = {token.pos: token.pos_ for token in raw_doc}\n",
    "print(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b32810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3773ff0c493e4809bb10a9f97daba356-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">never</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">playing ,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">reading</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">her</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">hobby</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3773ff0c493e4809bb10a9f97daba356-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3773ff0c493e4809bb10a9f97daba356-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing displacy\n",
    "from spacy import displacy\n",
    "my_text='She never like playing , reading was her hobby'\n",
    "my_doc=nlp(my_text)\n",
    "\n",
    "# displaying tokens with their POS tags\n",
    "displacy.render(my_doc,style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b321c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tony Stark, Clark, Microsoft, Bible, French)\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "# Preparing the spaCy document\n",
    "text='Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French'\n",
    "doc=nlp(text)\n",
    "\n",
    "# Printing the named entities\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85120491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERSON : Denotes names of people\n",
    "# GPE : Denotes places like counties, cities, states.\n",
    "# ORG : Denotes organizations or companies\n",
    "# WORK_OF_ART : Denotes titles of books, fimls,songs and other arts\n",
    "# PRODUCT : Denotes products such as vehicles, food items ,furniture and so on.\n",
    "# EVENT : Denotes historical events like wars, disasters ,etc…\n",
    "# LANGUAGE : All the recognized languages across the globe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c49e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony Stark ---  PERSON\n",
      "Clark ---  PERSON\n",
      "Microsoft ---  ORG\n",
      "Bible ---  WORK_OF_ART\n",
      "French ---  LANGUAGE\n"
     ]
    }
   ],
   "source": [
    "# Printing labels of entities.\n",
    "for entity in doc.ents:\n",
    "  print(entity.text,'--- ',entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c15b03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tony Stark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " owns the company StarkEnterprises . Emily \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Clark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and lives in Manchester. She loves to read the \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " and learn \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    French\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using displacy for visualizing NER\n",
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d5da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER Application 1: Extracting brand names with Named Entity Recognition\n",
    "mobile_industry_article=\"\"\" 30 Major mobile phone brands Compete in India – A Case Study of Success and Failures\n",
    "Is the Indian mobile market a terrible War Zone? We have more than 30 brands competing with each other. \n",
    "Let’s find out some insights about the world second-largest mobile bazaar.\n",
    "There is a massive invasion by Chinese mobile brands in India in the last four years. \n",
    "Some of the brands have been able to make a mark while others like Meizu, Coolpad, ZTE, and LeEco are a failure.\n",
    "On one side, there are brands like Sony or HTC that have quit from the Indian market on the other side we have new brands like Realme or iQOO entering the marketing in recent months.\n",
    "The mobile market is so competitive that some of the brands like Micromax, which had over 18% share back in 2014, now have less than 5%. \n",
    "Even the market leader Samsung with a 34% market share in 2014, now has a 21% share whereas Xiaomi has become a market leader. \n",
    "The battle is fierce and to sustain and scale-up is going to be very difficult for any new entrant.\n",
    "new comers in Indian Mobile MarketiQOO –They have recently (March 2020) launched the iQOO 3 in India with its first 5G phone – iQOO 3. \n",
    "The new brand is part of the Vivo or the BBK electronics group that also owns several other brands like Oppo, Oneplus and Realme.Realme – Realme launched the first-ever phone – Realme 1 in November 2018 and has quickly became a popular brand in India. The brand is one of the highest sellers in online space and even reached a 16% market share threatening Xiaomi’s dominance.iVoomi – In 2017, we have seen the entry of some new Chinese mobile brands likeiVoomi which focuses on the sub 10k price range, and is a popular online player. They have an association with Flipkart.Techno &amp; Infinix – Transsion Group’s Tecno and Infinix brands debuted in India in mid-2017 and are focusing on the low end and mid-range phones in the price range of Rs. 5000 to Rs. 12000.10.OR &amp; Lephone – 10.OR has a partnership with Amazon India and is an exclusive online brand with phones like 10.OR D, G and E. However, the brand is not very aggressive currently.Kult – Kult is another player who launched a very aggressively priced Kult Beyond mobile in 2017 and followed up by launching 2-3 more models.However, most of these new brands are finding it difficult to strengthen their footing in India. As big brands like Xiaomi leave no stone unturned to make things difficult.Also, it is worth noting that there is less Chinese players coming to India now. As either all the big brands have already set shop or burnt their hands and retreated to the homeland China.Chinese/ Global  Brands Which failed or are at the Verge of Failing in India?\n",
    "There are a lot more failures in the market than the success stories. \n",
    "Let’s first look at the failures and then we will also discuss why some brands were able to succeed in India.\n",
    "HTC – The biggest surprise this year for me was the failure of HTC in India. \n",
    "The brand has been in the country for many years, in fact, they were the first brand to launch Android mobiles. \n",
    "Finally HTC decided to call it a day in July 2018.LeEco – LeEco looked promising and even threatening to Xiaomi when it came to India. \n",
    "The company launched a series of new phones and smart TVs at affordable rates. Unfortunately, poor financial planning back home caused the brand to fail in India too.\n",
    "LG – The company seems to have lost focus and are doing poorly in all segments. \n",
    "While the budget and mid-range offering are uncompetitive, the high-end models are not preferred by buyers.\n",
    "Sony – Absurd pricing and lack of ability to understand the Indian buyers have caused Sony to shrink mobile operations in India. \n",
    "In the last 2 years, there are far fewer launches and hardly any promotions or hype around the new products.\n",
    "Meizu – Meizu is also a struggling brand in India and is going nowhere with the current strategy. \n",
    "There are hardly any popular mobiles nor a retail presence.\n",
    "ZTE – The company was aggressive till last year with several new phones launching under the Nubia banner, but with recent issues in the US, they have even lost the plot in India.\n",
    "Coolpad – I still remember the first meeting with Coolpad CEO in Mumbai when the brand started operations. There were big dreams and ambitions, but the company has not been able to deliver and keep up with the rivals in the last 1 year.Gionee – Gionee was doing well in the retail, but the infighting in the company and loss of focus from the Chinese parent company has made it a failure. The company is planning a comeback. However, we will have to wait and see when that happens.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0ea178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZTE', 'Sony', 'Realme', 'Micromax', 'BBK', 'Oppo, Oneplus and Realme', 'Realme', 'Realme', 'Xiaomi’s', 'Flipkart.', 'Infinix – Transsion Group’s', 'Infinix', 'Lephone', 'Amazon India', 'Xiaomi', 'the Verge of Failing', 'Android', 'Sony', 'Sony', 'ZTE']\n"
     ]
    }
   ],
   "source": [
    "# creating spacy doc\n",
    "mobile_doc=nlp(mobile_industry_article)\n",
    "\n",
    "# List to store name of mobile companies\n",
    "list_of_org=[]\n",
    "\n",
    "# Appending entities which havel the label 'ORG' to the list\n",
    "for entity in mobile_doc.ents:\n",
    "  if entity.label_=='ORG':\n",
    "    list_of_org.append(entity.text)\n",
    "\n",
    "print(list_of_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d1ebeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER Application 2: Automatically Masking Entities\n",
    "news_text=\"\"\"Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to Hyderabad, according to a media report on Saturday.Yogesh Ashok Yariava, the prime accused in the fraud, flew from Abu Dhabi to Hyderabad on a Vande Bharat repatriation flight on May 11 with around 170 evacuees, the Gulf News reported.Yariava, the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to India, the daily said.\n",
    "The bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).\n",
    "The list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.\n",
    "The aggrieved traders have filed a case with the Bur Dubai police station.\n",
    "The traders said when the dud cheques started bouncing they rushed to the Royal Luck's office in Dubai but the shutters were down, even the fraudulent company's warehouses were empty.\"\"\"\n",
    "\n",
    "news_doc=nlp(news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70e92f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to  UNKNOWN  , according to a media report on Saturday .  UNKNOWN  , the prime accused in the fraud , flew from  UNKNOWN   UNKNOWN  repatriation flight on May 11 with around 170 evacuees ,  UNKNOWN  reported .  UNKNOWN  , the 36-year-old owner of the fraudulent  UNKNOWN  , made bulk purchases worth 6 million dirhams ( USD 1.6 million ) against post - dated cheques from unsuspecting traders before fleeing to  UNKNOWN  , the daily said . \\n The bought goods included facemasks , hand sanitisers , medical gloves ( worth nearly 5,00,000 dirhams ) , rice and nuts ( 3,93,000 dirhams ) , tuna , pistachios and saffron ( 3,00,725 dirhams ) , French fries and mozzarella cheese ( 2,29,000 dirhams ) , frozen Indian beef ( 2,07,000 dirhams ) and halwa and tahina ( 52,812 dirhams ) . \\n The list of items and defrauded persons keeps getting longer as more and more victims come forward , the report said . \\n The aggrieved traders have filed a case with  UNKNOWN  police station . \\n The traders said when the dud cheques started bouncing they rushed to the Royal Luck 's office in  UNKNOWN  but the shutters were down , even the fraudulent company 's warehouses were empty .\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to identify  if tokens are named entities and replace them with UNKNOWN\n",
    "def remove_details(word):\n",
    "  if word.ent_type_ =='PERSON' or word.ent_type_=='ORG' or word.ent_type_=='GPE':\n",
    "    return ' UNKNOWN '\n",
    "  return str(word)\n",
    "\n",
    "\n",
    "# Function where each token of spacy doc is passed through remove_deatils()\n",
    "def update_article(doc):\n",
    "  # iterrating through all entities\n",
    "  with doc.retokenize() as retokenizer:\n",
    "        for ent in doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "  # Passing each token through remove_details() function.\n",
    "  tokens = map(remove_details,doc)\n",
    "  return ' '.join(tokens)\n",
    "\n",
    "# Passing our news_doc to the function update_article()\n",
    "update_article(news_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4bf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rule based Matching\n",
    "# There will be situations like these, where you’ll need extract specific pattern type phrases from the text. \n",
    "# This is called Rule-based matching.\n",
    "# 3 Types\n",
    "# Token Matcher\n",
    "# Phrase Matcher\n",
    "# Entity Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da034386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Token Matcher\n",
    "# The procedure to implement a token matcher is:\n",
    "\n",
    "# Initialize a Matcher object\n",
    "# Define the pattern you want to match\n",
    "# Add the pattern to the matcher\n",
    "# Pass the text to the matcher to extract the matching positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcd863b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.matcher.matcher.Matcher at 0x2a9388d3dc8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher \n",
    "# Initializing the matcher with vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "946fece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the matching pattern\n",
    "my_pattern=[{\"LOWER\": \"version\"}, {\"IS_PUNCT\": True}, {\"LIKE_NUM\": True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27e1a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the token matcher\n",
    "matcher.add('VersionFinder', [my_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f60cf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6950581368505071052, 1, 4),\n",
       " (6950581368505071052, 27, 30),\n",
       " (6950581368505071052, 65, 68)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Token Matcher\n",
    "my_text = 'The version : 6 of the app was released about a year back and was not very sucessful. As a comeback, six months ago, version : 7 was released and it took the stage. After that , the app has has the limelight till now. On interviewing some sources, we get to know that they have outlined visiond till version : 12 ,the Ultimate.'\n",
    "my_doc = nlp(my_text)\n",
    "\n",
    "desired_matches = matcher(my_doc)\n",
    "desired_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fbb6c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version : 6\n",
      "version : 7\n",
      "version : 12\n"
     ]
    }
   ],
   "source": [
    "# Extract the matches\n",
    "for match_id, start, end in desired_matches :\n",
    "    string_id = nlp.vocab.strings[match_id] \n",
    "    span = my_doc[start:end] \n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18d8c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " matches found: 4\n",
      "Match found: visited Manali\n",
      "Match found: visiting Ladakh\n",
      "Match found: visiting NewYork\n",
      "Match found: visited Kodaikanal\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "text = \"\"\"I visited Manali last time. Around same budget trips ? \"\n",
    "    I was visiting Ladakh this summer \"\n",
    "    I have planned visiting NewYork and other abroad places for next year\"\n",
    "    Have you ever visited Kodaikanal? \"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Initialize the matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Write a pattern that matches a form of \"visit\" + place\n",
    "my_pattern = [{\"LEMMA\": \"visit\"}, {\"POS\": \"PROPN\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"Visting_places\", [my_pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Counting the no of matches\n",
    "print(\" matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3736c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3\n",
    "engineering_text = \"\"\"If you study aeronautical engineering, you could specialize in aerodynamics, aeroelasticity, \n",
    "composites analysis, avionics, propulsion and structures and materials. If you choose to study chemical engineering, you may like to\n",
    "specialize in chemical reaction engineering, plant design, process engineering, process design or transport phenomena. Civil engineering is the professional practice of designing and developing infrastructure projects. This can be on a huge scale, such as the development of\n",
    "nationwide transport systems or water supply networks, or on a smaller scale, such as the development of single roads or buildings.\n",
    "specializations of civil engineering include structural engineering, architectural engineering, transportation engineering, geotechnical engineering,\n",
    "environmental engineering and hydraulic engineering. Computer engineering concerns the design and prototyping of computing hardware and software. \n",
    "This subject merges electrical engineering with computer science, oldest and broadest types of engineering, mechanical engineering is concerned with the design,\n",
    "manufacturing and maintenance of mechanical systems. You’ll study statics and dynamics, thermodynamics, fluid dynamics, stress analysis, mechanical design and\n",
    "technical drawing\"\"\"\n",
    "\n",
    "doc = nlp(engineering_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed796bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 15\n",
      "Match found: aeronautical engineering\n",
      "Match found: chemical engineering\n",
      "Match found: reaction engineering\n",
      "Match found: process engineering\n",
      "Match found: Civil engineering\n",
      "Match found: civil engineering\n",
      "Match found: structural engineering\n",
      "Match found: architectural engineering\n",
      "Match found: transportation engineering\n",
      "Match found: geotechnical engineering\n",
      "Match found: environmental engineering\n",
      "Match found: hydraulic engineering\n",
      "Match found: Computer engineering\n",
      "Match found: electrical engineering\n",
      "Match found: mechanical engineering\n"
     ]
    }
   ],
   "source": [
    "# Initializing the matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Write a pattern that matches a form of \"noun/adjective\"+\"engineering\"\n",
    "my_pattern = [{\"POS\": {\"IN\": [\"NOUN\", \"ADJ\"]}}, {\"LOWER\": \"engineering\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"identify_courses\", [my_pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the matching text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bb125f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase Matcher\n",
    "# The procedure to use PhraseMatcher is very similar to Matcher.\n",
    "\n",
    "# Initialize a PhraseMatcher object with a vocab.\n",
    "# Define the terms you want to match\n",
    "# Add the pattern to the matcher\n",
    "# Run the text through the matcher to extract the matching positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc6bed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "# Terms to match\n",
    "terms_list = ['Bruce Wayne', 'Tony Stark', 'Batman', 'Harry Potter', 'Severus Snape']\n",
    "\n",
    "# Make a list of docs\n",
    "patterns = [nlp.make_doc(text) for text in terms_list]\n",
    "\n",
    "matcher.add(\"phrase_matcher\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1d181ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matcher Object\n",
    "fictional_char_doc = nlp(\"\"\"Superman (first appearance: 1938)  Created by Jerry Siegal and Joe Shuster for Action Comics #1 (DC Comics).Mickey Mouse (1928)  Created by Walt Disney and Ub Iworks for Steamboat Willie.Bugs Bunny (1940)  Created by Warner Bros and originally voiced by Mel Blanc.Batman (1939) Created by Bill Finger and Bob Kane for Detective Comics #27 (DC Comics).\n",
    "Dorothy Gale (1900)  Created by L. Frank Baum for novel The Wonderful Wizard of Oz. Later portrayed by Judy Garland in the 1939 film adaptation.Darth Vader (1977) Created by George Lucas for Star Wars IV: A New Hope.The Tramp (1914)  Created and portrayed by Charlie Chaplin for Kid Auto Races at Venice.Peter Pan (1902)  Created by J.M. Barrie for novel The Little White Bird.\n",
    "Indiana Jones (1981)  Created by George Lucas for Raiders of the Lost Ark. Portrayed by Harrison Ford.Rocky Balboa (1976)  Created and portrayed by Sylvester Stallone for Rocky.Vito Corleone (1969) Created by Mario Puzo for novel The Godfather. Later portrayed by Marlon Brando and Robert DeNiro in Coppola’s film adaptation.Han Solo (1977) Created by George Lucas for Star Wars IV: A New Hope. \n",
    "Portrayed most famously by Harrison Ford.Homer Simpson (1987)  Created by Matt Groening for The Tracey Ullman Show, later The Simpsons as voiced by Dan Castellaneta.Archie Bunker (1971) Created by Norman Lear for All in the Family. Portrayed by Carroll O’Connor.Norman Bates (1959) Created by Robert Bloch for novel Psycho.  Later portrayed by Anthony Perkins in Hitchcock’s film adaptation.King Kong (1933) \n",
    "Created by Edgar Wallace and Merian C Cooper for the film King Kong.Lucy Ricardo (1951) Portrayed by Lucille Ball for I Love Lucy.Spiderman (1962)  Created by Stan Lee and Steve Ditko for Amazing Fantasy #15 (Marvel Comics).Barbie (1959)  Created by Ruth Handler for the toy company Mattel Spock (1964)  Created by Gene Roddenberry for Star Trek. Portrayed most famously by Leonard Nimoy.\n",
    "Godzilla (1954) Created by Tomoyuki Tanaka, Ishiro Honda, and Eiji Tsubaraya for the film Godzilla.The Joker (1940)  Created by Jerry Robinson, Bill Finger, and Bob Kane for Batman #1 (DC Comics)Winnie-the-Pooh (1924)  Created by A.A. Milne for verse book When We Were Young.Popeye (1929)  Created by E.C. Segar for comic strip Thimble Theater (King Features).Tarzan (1912) Created by Edgar Rice Burroughs for the novel Tarzan of the Apes.Forrest Gump (1986)  Created by Winston Groom for novel Forrest Gump.  Later portrayed by Tom Hanks in Zemeckis’ film adaptation.Hannibal Lector (1981)  Created by Thomas Harris for the novel Red Dragon. Portrayed most famously by Anthony Hopkins in the 1991 Jonathan Demme film The Silence of the Lambs.\n",
    "Big Bird (1969) Created by Jim Henson and portrayed by Carroll Spinney for Sesame Street.Holden Caulfield (1945) Created by J.D. Salinger for the Collier’s story “I’m Crazy.”  Reworked into the novel The Catcher in the Rye in 1951.Tony Montana (1983)  Created by Oliver Stone for film Scarface.  Portrayed by Al Pacino.Tony Soprano (1999)  Created by David Chase for The Sopranos. Portrayed by James Gandolfini.\n",
    "The Terminator (1984)  Created by James Cameron and Gale Anne Hurd for The Terminator. Portrayed by Arnold Schwarzenegger.Jon Snow (1996)  Created by George RR Martin for the novel The Game of Thrones.  Portrayed by Kit Harrington.Charles Foster Kane (1941)  Created and portrayed by Orson Welles for Citizen Kane.Scarlett O’Hara (1936)  Created by Margaret Mitchell for the novel Gone With the Wind. Portrayed most famously by Vivien Leigh \n",
    "for the 1939 Victor Fleming film adaptation.Marty McFly (1985) Created by Robert Zemeckis and Bob Gale for Back to the Future. Portrayed by Michael J. Fox.Rick Blaine (1940)  Created by Murray Burnett and Joan Alison for the unproduced stage play Everybody Comes to Rick’s. Later portrayed by Humphrey Bogart in Michael Curtiz’s film adaptation Casablanca.Man With No Name (1964)  Created by Sergio Leone for A Fistful of Dollars, which was adapted from a ronin character in Kurosawa’s Yojimbo (1961).  Portrayed by Clint Eastwood.Charlie Brown (1948)  Created by Charles M. Shultz for the comic strip L’il Folks; popularized two years later in Peanuts.E.T. (1982)  Created by Melissa Mathison for the film E.T.: the Extra-Terrestrial.Arthur Fonzarelli (1974)  Created by Bob Brunner for the show Happy Days. Portrayed by Henry Winkler.)Phillip Marlowe (1939)  Created by Raymond Chandler for the novel The Big Sleep.Jay Gatsby (1925)  Created by F. Scott Fitzgerald for the novel The Great Gatsby.Lassie (1938) Created by Eric Knight for a Saturday Evening Post story, later turned into the novel Lassie Come-Home in 1940, film adaptation in 1943, and long-running television show in 1954.  Most famously portrayed by the dog Pal.\n",
    "Fred Flintstone (1959)  Created by William Hanna and Joseph Barbera for The Flintstones. Voiced most notably by Alan Reed. Rooster Cogburn (1968)  Created by Charles Portis for the novel True Grit. Most famously portrayed by John Wayne in the 1969 film adaptation. Atticus Finch (1960)  Created by Harper Lee for the novel To Kill a Mockingbird.  (Appeared in the earlier work Go Set A Watchman, though this was not published until 2015)  Portrayed most famously by Gregory Peck in the Robert Mulligan film adaptation. Kermit the Frog (1955)  Created and performed by Jim Henson for the show Sam and Friends. Later popularized in Sesame Street (1969) and The Muppet Show (1976) George Bailey (1943)  Created by Phillip Van Doren Stern (then as George Pratt) for the short story The Greatest Gift. Later adapted into Capra’s It’s A Wonderful Life, starring James Stewart as the renamed George Bailey. Yoda (1980) Created by George Lucas for The Empire Strikes Back. Sam Malone (1982)  Created by Glen and Les Charles for the show Cheers.  Portrayed by Ted Danson. Zorro (1919)  Created by Johnston McCulley for the All-Story Weekly pulp magazine story The Curse of Capistrano.Later adapted to the Douglas Fairbanks’ film The Mark of Zorro (1920).Moe, Larry, and Curly (1928)  Created by Ted Healy for the vaudeville act Ted Healy and his Stooges. Mary Poppins (1934)  Created by P.L. Travers for the children’s book Mary Poppins. Ron Burgundy (2004)  Created by Will Ferrell and Adam McKay for the film Anchorman: The Legend of Ron Burgundy.  Portrayed by Will Ferrell. Mario (1981)  Created by Shigeru Miyamoto for the video game Donkey Kong. Harry Potter (1997)  Created by J.K. Rowling for the novel Harry Potter and the Philosopher’s Stone. The Dude (1998)  Created by Ethan and Joel Coen for the film The Big Lebowski. Portrayed by Jeff Bridges.\n",
    "Gandalf (1937)  Created by J.R.R. Tolkien for the novel The Hobbit. The Grinch (1957)  Created by Dr. Seuss for the story How the Grinch Stole Christmas! Willy Wonka (1964)  Created by Roald Dahl for the children’s novel Charlie and the Chocolate Factory. The Hulk (1962)  Created by Stan Lee and Jack Kirby for The Incredible Hulk #1 (Marvel Comics) Scooby-Doo (1969)  Created by Joe Ruby and Ken Spears for the show Scooby-Doo, Where Are You! George Costanza (1989)  Created by Larry David and Jerry Seinfeld for the show Seinfeld.  Portrayed by Jason Alexander.Jules Winfield (1994)  Created by Quentin Tarantino for the film Pulp Fiction. Portrayed by Samuel L. Jackson. John McClane (1988)  Based on the character Detective Joe Leland, who was created by Roderick Thorp for the novel Nothing Lasts Forever. Later adapted into the John McTernan film Die Hard, starring Bruce Willis as McClane. Ellen Ripley (1979)  Created by Don O’cannon and Ronald Shusett for the film Alien.  Portrayed by Sigourney Weaver. Ralph Kramden (1951)  Created and portrayed by Jackie Gleason for “The Honeymooners,” which became its own show in 1955.Edward Scissorhands (1990)  Created by Tim Burton for the film Edward Scissorhands.  Portrayed by Johnny Depp.Eric Cartman (1992)  Created by Trey Parker and Matt Stone for the animated short Jesus vs Frosty.  Later developed into the show South Park, which premiered in 1997.  Voiced by Trey Parker.\n",
    "Walter White (2008)  Created by Vince Gilligan for Breaking Bad.  Portrayed by Bryan Cranston. Cosmo Kramer (1989)  Created by Larry David and Jerry Seinfeld for Seinfeld.  Portrayed by Michael Richards.Pikachu (1996)  Created by Atsuko Nishida and Ken Sugimori for the Pokemon video game and anime franchise.Michael Scott (2005)  Based on a character from the British series The Office, created by Ricky Gervais and Steven Merchant.  Portrayed by Steve Carell.Freddy Krueger (1984)  Created by Wes Craven for the film A Nightmare on Elm Street. Most famously portrayed by Robert Englund.\n",
    "Captain America (1941)  Created by Joe Simon and Jack Kirby for Captain America Comics #1 (Marvel Comics)Goku (1984)  Created by Akira Toriyama for the manga series Dragon Ball Z.Bambi (1923)  Created by Felix Salten for the children’s book Bambi, a Life in the Woods. Later adapted into the Disney film Bambi in 1942.Ronald McDonald (1963) Created by Williard Scott for a series of television spots.Waldo/Wally (1987) Created by Martin Hanford for the children’s book Where’s Wally? (Waldo in US edition) Frasier Crane (1984)  Created by Glen and Les Charles for Cheers.  Portrayed by Kelsey Grammar.Omar Little (2002)  Created by David Simon for The Wire.Portrayed by Michael K. Williams.\n",
    "Wolverine (1974)  Created by Roy Thomas, Len Wein, and John Romita Sr for The Incredible Hulk #180 (Marvel Comics) Jason Voorhees (1980)  Created by Victor Miller for the film Friday the 13th. Betty Boop (1930)  Created by Max Fleischer and the Grim Network for the cartoon Dizzy Dishes. Bilbo Baggins (1937)  Created by J.R.R. Tolkien for the novel The Hobbit. Tom Joad (1939)  Created by John Steinbeck for the novel The Grapes of Wrath. Later adapted into the 1940 John Ford film and portrayed by Henry Fonda.Tony Stark (Iron Man) (1963)  Created by Stan Lee, Larry Lieber, Don Heck and Jack Kirby for Tales of Suspense #39 (Marvel Comics)Porky Pig (1935)  Created by Friz Freleng for the animated short film I Haven’t Got a Hat. Voiced most famously by Mel Blanc.Travis Bickle (1976)  Created by Paul Schrader for the film Taxi Driver. Portrayed by Robert De Niro.\n",
    "Hawkeye Pierce (1968)  Created by Richard Hooker for the novel MASH: A Novel About Three Army Doctors.  Famously portrayed by both Alan Alda and Donald Sutherland. Don Draper (2007)  Created by Matthew Weiner for the show Mad Men.  Portrayed by Jon Hamm. Cliff Huxtable (1984)  Created and portrayed by Bill Cosby for The Cosby Show. Jack Torrance (1977)  Created by Stephen King for the novel The Shining. Later adapted into the 1980 Stanley Kubrick film and portrayed by Jack Nicholson. Holly Golightly (1958)  Created by Truman Capote for the novella Breakfast at Tiffany’s.  Later adapted into the 1961 Blake Edwards films starring Audrey Hepburn as Holly. Shrek (1990)  Created by William Steig for the children’s book Shrek! Later adapted into the 2001 film starring Mike Myers as the titular character. Optimus Prime (1984)  Created by Dennis O’Neil for the Transformers toy line.Sonic the Hedgehog (1991)  Created by Naoto Ohshima and Yuji Uekawa for the Sega Genesis game of the same name.Harry Callahan (1971)  Created by Harry Julian Fink and R.M. Fink for the movie Dirty Harry.  Portrayed by Clint Eastwood.Bubble: Hercule Poirot, Tyrion Lannister, Ron Swanson, Cercei Lannister, J.R. Ewing, Tyler Durden, Spongebob Squarepants, The Genie from Aladdin, Pac-Man, Axel Foley, Terry Malloy, Patrick Bateman\n",
    "Pre-20th Century: Santa Claus, Dracula, Robin Hood, Cinderella, Huckleberry Finn, Odysseus, Sherlock Holmes, Romeo and Juliet, Frankenstein, Prince Hamlet, Uncle Sam, Paul Bunyan, Tom Sawyer, Pinocchio, Oliver Twist, Snow White, Don Quixote, Rip Van Winkle, Ebenezer Scrooge, Anna Karenina, Ichabod Crane, John Henry, The Tooth Fairy,\n",
    "Br’er Rabbit, Long John Silver, The Mad Hatter, Quasimodo \"\"\")\n",
    "\n",
    "\n",
    "character_matches = matcher(fictional_char_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ab6d9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(520014689628841516, 56, 57),\n",
       " (520014689628841516, 449, 450),\n",
       " (520014689628841516, 1352, 1354),\n",
       " (520014689628841516, 1365, 1367),\n",
       " (520014689628841516, 2084, 2086)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching positions\n",
    "character_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33191b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batman\n",
      "Batman\n",
      "Harry Potter\n",
      "Harry Potter\n",
      "Tony Stark\n"
     ]
    }
   ],
   "source": [
    "# Matched items\n",
    "for match_id, start, end in character_matches:\n",
    "    span = fictional_char_doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5edf0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york\n"
     ]
    }
   ],
   "source": [
    "# Using the attr parameter as 'LOWER'\n",
    "case_insensitive_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "# Creating doc &amp; pattern\n",
    "my_doc=nlp('I wish to visit new york city')\n",
    "terms=['New York']\n",
    "pattern=[nlp(term) for term in terms]\n",
    "\n",
    "# adding pattern to the matcher\n",
    "case_insensitive_matcher.add(\"matcher\",None,*pattern)\n",
    "\n",
    "# applying matcher to the doc\n",
    "my_matches=case_insensitive_matcher(my_doc)\n",
    "\n",
    "for match_id,start,end in my_matches:\n",
    "  span=my_doc[start:end]\n",
    "  print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f88fc220",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc = nlp('From 8 am , Mr.X will be speaking on your favorite chanel 191.1. Afterward there shall be an exclusive interview with actor Vijay on channel 194.1 . Hope you are having a great day. Call us on 666666')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffb3ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191.1\n",
      "194.1\n"
     ]
    }
   ],
   "source": [
    "pattern=nlp('154.6')\n",
    "\n",
    "# Initializing the matcher and adding pattern\n",
    "pincode_matcher= PhraseMatcher(nlp.vocab,attr=\"SHAPE\")\n",
    "pincode_matcher.add(\"pincode_matching\", [pattern])\n",
    "\n",
    "# Applying matcher on doc\n",
    "matches = pincode_matcher(my_doc)\n",
    "\n",
    "# Printing the matched phrases\n",
    "for match_id, start, end in matches:\n",
    "  span = my_doc[start:end]\n",
    "  print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e64c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Entity Ruler\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Initialize\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "pattern=[{\"label\": \"WORK_OF_ART\", \"pattern\": \"My guide to statistics\"}]\n",
    "\n",
    "ruler.add_patterns(pattern)\n",
    "\n",
    "\n",
    "# Add entity ruler to the NLP pipeline. \n",
    "# NLP pipeline is a sequence of NLP tasks that spaCy performs for a given text\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "# Extract the custom entity type \n",
    "doc = nlp(\" I recently published my work fanfiction by Dr.X . Right now I'm studying the book of my friend .You should try My guide to statistics for clear concepts.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74642035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between review 1 and 2 0.8043222830391739\n",
      "Similarity between review 3 and 4 0.37536336289068906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\vfdpqa8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \n",
      "D:\\Users\\vfdpqa8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "review_1=nlp(' The food was amazing')\n",
    "review_2=nlp('The food was excellent')\n",
    "review_3=nlp('I did not like the food')\n",
    "review_4=nlp('It was very bad experience')\n",
    "\n",
    "score_1=review_1.similarity(review_2)\n",
    "print('Similarity between review 1 and 2',score_1)\n",
    "\n",
    "score_2=review_1.similarity(review_4)\n",
    "print('Similarity between review 3 and 4',score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6387f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza and burger   0.6785067815137173\n",
      "Pizza and chair   0.8884922946704111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\vfdpqa8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \n",
      "D:\\Users\\vfdpqa8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Compute Similarity between texts \n",
    "pizza=nlp('pizza')\n",
    "burger=nlp('burger')\n",
    "chair=nlp('chair')\n",
    "\n",
    "print('Pizza and burger  ',pizza.similarity(burger))\n",
    "print('Pizza and chair  ',pizza.similarity(chair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5fdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
